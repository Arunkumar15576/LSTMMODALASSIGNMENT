{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9R6NwMPnS_K",
        "outputId": "ead38c18-3c31-4913-f62c-00ce2b8fa07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BO] Iter 1/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 2/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 3/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 4/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 5/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 6/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 7/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 8/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 9/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 10/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 11/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 12/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 13/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 14/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 15/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 16/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 17/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 18/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 19/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 20/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 21/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 22/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 23/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 24/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 25/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 26/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 27/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 28/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 29/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 30/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 31/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 32/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 33/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 34/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 35/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 36/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 37/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 38/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 39/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 40/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 41/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 42/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 43/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 44/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 45/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 46/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 47/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 48/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 49/50 | Best RMSE = 0.4437\n",
            "[BO] Iter 50/50 | Best RMSE = 0.4437\n",
            "\n",
            "===== FINAL RESULTS =====\n",
            "Best RMSE: 0.4436811604684309\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Pure Python + NumPy + SciPy Bayesian Optimization\n",
        "Gaussian Process + Expected Improvement + XGBoost\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.linalg import cholesky, solve\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import random\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 1. Load dataset\n",
        "# =====================================\n",
        "data = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.data, data.target, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 2. Gaussian Process Kernel (Matern 5/2)\n",
        "# =====================================\n",
        "def matern52_kernel(X1, X2, l=1.0, sigma_f=1.0):\n",
        "    r = cdist(X1, X2, metric='euclidean')\n",
        "    sqrt5_r = np.sqrt(5) * r\n",
        "    return sigma_f**2 * (1 + sqrt5_r + (5/3)*r**2) * np.exp(-sqrt5_r)\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 3. GP Prediction\n",
        "# =====================================\n",
        "def gp_predict(X_train, y_train, X_test, l=1.0, sigma_f=1.0, sigma_n=1e-6):\n",
        "    K = matern52_kernel(X_train, X_train, l, sigma_f) + sigma_n*np.eye(len(X_train))\n",
        "    K_s = matern52_kernel(X_train, X_test, l, sigma_f)\n",
        "    K_ss = matern52_kernel(X_test, X_test, l, sigma_f) + 1e-8*np.eye(len(X_test))\n",
        "\n",
        "    L = cholesky(K, lower=True)\n",
        "    alpha = solve(L.T, solve(L, y_train))\n",
        "\n",
        "    mu = K_s.T @ alpha\n",
        "    v = solve(L, K_s)\n",
        "    cov = K_ss - v.T @ v\n",
        "    sigma = np.sqrt(np.maximum(np.diag(cov), 1e-9))\n",
        "    return mu, sigma\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 4. Expected Improvement (EI)\n",
        "# =====================================\n",
        "from scipy.stats import norm\n",
        "\n",
        "def expected_improvement(mu, sigma, f_best, xi=0.01):\n",
        "    Z = (f_best - mu - xi) / sigma\n",
        "    EI = (f_best - mu - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
        "    EI[sigma == 0.0] = 0.0\n",
        "    return EI\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 5. Objective Function Wrapper for XGBoost\n",
        "# =====================================\n",
        "def objective(params):\n",
        "    (max_depth, lr, n_est, subs, col) = params\n",
        "\n",
        "    model = XGBRegressor(\n",
        "        max_depth=int(max_depth),\n",
        "        learning_rate=float(lr),\n",
        "        n_estimators=int(n_est),\n",
        "        subsample=float(subs),\n",
        "        colsample_bytree=float(col),\n",
        "        tree_method=\"hist\",\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    return rmse\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 6. Define search space\n",
        "# =====================================\n",
        "bounds = np.array([\n",
        "    [3, 12],        # max_depth\n",
        "    [0.01, 0.3],    # learning_rate\n",
        "    [100, 600],     # n_estimators\n",
        "    [0.5, 1.0],     # subsample\n",
        "    [0.5, 1.0],     # colsample_bytree\n",
        "])\n",
        "\n",
        "\n",
        "# Random sample\n",
        "def sample_random():\n",
        "    return np.array([\n",
        "        np.random.randint(bounds[0][0], bounds[0][1]+1),\n",
        "        np.random.uniform(bounds[1][0], bounds[1][1]),\n",
        "        np.random.randint(bounds[2][0], bounds[2][1]+1),\n",
        "        np.random.uniform(bounds[3][0], bounds[3][1]),\n",
        "        np.random.uniform(bounds[4][0], bounds[4][1]),\n",
        "    ])\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 7. Bayesian Optimization Loop\n",
        "# =====================================\n",
        "N_INIT = 5\n",
        "N_ITER = 50\n",
        "\n",
        "X_obs = []\n",
        "y_obs = []\n",
        "\n",
        "# ---- Initial random points\n",
        "for _ in range(N_INIT):\n",
        "    x = sample_random()\n",
        "    y = objective(x)\n",
        "    X_obs.append(x)\n",
        "    y_obs.append(y)\n",
        "\n",
        "X_obs = np.array(X_obs)\n",
        "y_obs = np.array(y_obs)\n",
        "\n",
        "\n",
        "for t in range(N_ITER):\n",
        "    # Candidate pool\n",
        "    candidates = np.array([sample_random() for _ in range(200)])\n",
        "\n",
        "    mu, sigma = gp_predict(X_obs, y_obs, candidates)\n",
        "\n",
        "    f_best = np.min(y_obs)\n",
        "    EI = expected_improvement(mu, sigma, f_best)\n",
        "\n",
        "    next_idx = np.argmax(EI)\n",
        "    next_x = candidates[next_idx]\n",
        "\n",
        "    y_next = objective(next_x)\n",
        "\n",
        "    X_obs = np.vstack([X_obs, next_x])\n",
        "    y_obs = np.append(y_obs, y_next)\n",
        "\n",
        "    print(f\"[BO] Iter {t+1}/{N_ITER} | Best RMSE = {np.min(y_obs):.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n===== FINAL RESULTS =====\")\n",
        "print(\"Best RMSE:\", np.min(y_obs))\n"
      ]
    }
  ]
}
